// SPDX-License-Identifier: Apache-2.0
:doctype: article

== UL

UL is a Universal Language, in the following senses:

* Reads its own code and translates it to other languages
* Run within an existing language (eg in Java as a ScriptEngine)
* Run as a CLI tool (use go get or copy a github release binary)
* Run as a shell language
* Run in Makefile for recipe lines
* Run in databases as a language for triggers, functions, procedures, new types/tables/indexes
* Run as a custom validation in a flexible app
* A UL script can just be a single line like ".Age < 100" to validate the Age field of the current object
* Written in UL

=== Key functional areas:

* Simple imperative code
* Easy to learn
* APIs for database access and HTTP client/server
* Code generation can be guided
** database function calls translated into Go database/sql, Java JDBC, etc
** HTTP serving translated into Go net/http, Java HttpHandler/HttpURLConnection
** Preprocessing via top level if statements that conditionally generate vars, functions, etc
** Some automatic constants suitable for preprocessing (eg SYSTEM_OS, SYSTEM_ARCH)
* Generate code for conversions, eg string -> int as Go strconv.Atoi, Java Integer.parseInt, etc
* Use json/yaml/toml to drive code generation
** Describe an object type
** Generate DTO structure
** Generate DAO for basic DTO handling (upsert, select, delete)
** Generate HTTP structure
** Generate REST API for basic operations (create/update, read, delete, patch), read only desired fields
** Generate all above in UL, which can then be used to generate target language
* Generate Dockerfile(s) with variations, such as:
** Local dev: podman with separate pods for database and API containers
** Local prod: podman with one pod for database and API containers, only API exposed
** Local embedded: podman with one pod for database/API container, where UL code translated into UL SQL procs and funcs
* Initially, work with following languages and databases:
** C, C#, F#, Go, Java
** DuckDB, MSSQL, MySQL, Oracle, Postgres

=== Language features:

* Built in maps, lists, primitives (including string and accurate decimal math), json/yaml/toml handling
* Define structs, procedures, funcs
* A struct can just be equal to another structure to act as a separate name for the same thing
* A struct can can be another structure plus additional fields
* An SQL like case statement
* As few operators as possible, no ++, /=, etc
* Uses wordy statements sometimes
** EG, to define DDL statements, text processing, json/yaml/toml handling
** UL code can create new words
* A grammar for parsing text
** Used to parse UL, including new words added by APIs
** Base UL only includes primitive types, structs, procs, funcs, grammar. Everything else is added using grammar parser.
** Parser used both for parsing external data (eg, JSON) as well as for extending UL to have new syntax.
** Core of UL is the core language and parser, remaining UL syntax is built by extending the parser.


=== Parser for core UL, and extending it

* Ignore whitespace
* Define rules that make up parsing
* Rule names are case sensitive, to allow for subtle distinctions
* A rule name can be referred to before it is defined, to support recursive definitions
  (eg, JSON arrays and objects can contain arrays and objects)
* Predefined rules for escapes for ascii control characters, quotes, and backslash
* Predefined rules all start with an _, as in _TAB_ESC
* A rule uses single quotes to surround literal character sequences - there are no escape sequences, making it easy
  to define escape sequences
* A character can be defined as U+HHHHHH outside of quotes
* A character range can be defined in square brackets, like [a-z]
** [a-z] means a .. z inclusive
** [a-] means a .. U+10FFFF inclusive
** [-a] means space .. a inclusive
** U+HHHHHH can be used, such that [U+000061-U+00007A] means the same as [a-z]
** Inside round brackets, a range can be followed by one or more - character or - range sequences to remove character(s) from the range
** [a-z] - x defines all lowercase letters except x
** [a-z] - [xy] defines all lowercase letters except x and y
** named ranges can be used
* Round brackets group rule parts together
* A rule or group can be followed by:
** ? to mean zero or one
** * to mean zero or more
** + to mean 1 or more
** {N} to mean exactly N
** {N,} to mean N or more
** {,M} to mean 0 to M times
** {N,M} to mean N to M times, inclusive
* A string range can be defined by a character range followed by {N,M}
** A string range can be followed by | and a pair of valid subsequences separated by ..
** If string _HEX4 = [0-9A-Fa-f]{4}, then string range _HEX4|D800 .. DBFF| means all strings four hex chars from D800 through DBFF
** Inside round brackets, a string range can be followed one or more - string range sequences to remove string range(s) from the string range
* A rule can have multiple lines, each of which can have multiple rules
** A line represents a valid sequence of rules
** Multiple lines represent multiple valid sequences to choose from
** Lines are tried in order for the first line that matches the input
** If all lines are exhausted, an error occurs
* Valid rules can be described as follows:
** strings: `varname = one line of string | char range | string range`
** orderings: `varname = one or more lines of string sequences, where each string is a literal or string var`
* Rules fit into two categories
** No whitespace: rules that define tokens, this is the initial mode
** Whitespace: rules that define grammar, which allow any amount of whitespace between tokens (preceded by `:GRAMMAR:`)
** Once the mode is switched to grammar, it cannot be switched back, for readability
** Last grammar rule is the top level rule for the language

Errors are generated automatically, by simply stating the following:

* The filename, line, and character position where the error occurred
* The last max 10 lines that were legal before the error occurred
* The token that failed - if the token contains non-printable ASCII chars, show Unicode U+HHHHHH hex sequence for them
* The set of possible rule names that could be used instead of the failed token

Allow for applying actions using core language.

Some builtin rules have builtin actions. EG, _utf16_ESC logically means a UTF16 character (the lowercase spelling
is due to expecting a lowercase u), but UTF can require up to 24 bits to represent a single character. UTF16 uses a
combination of high and low surrogate characters in that order, which together represent a single 24-bit character. It
is an error if a high surrogate is followed by anything but a low surrogate, or if a low surrogate is not preceded by a
high surrogate. These errors are handled by the builtin action.

Start with the following sequence on a line by itself, where <name> is a unique name provided:
DEFINE LANGUAGE <name>

End with the following sequence on a line by itself:
END LANGUAGE

=== Example rules that describe JSON

----
DEFINE LANGUAGE JSON	

// Builtin tokens of interest:
_TAB                  = U+000009
_LF                   = U+00000A
_CR                   = U+00000D
_BACKSPACE_ESC        = '\b'
_TAB_ESC              = '\t'
_LF_ESC               = '\n'
_FF_ESC               = '\f'
_CR_ESC               = '\r'
_DQUOTE_ESC           = '\"'
_SLASH_ESC            = '\/'
_BACKSLASH_ESC        = '\\'
_DIGIT                = [0-9]
_HEX                  = [0-9A-Fa-f]
_HEX4                 = _HEX{4}
_UTF16_HIGH_SURROGATE = _HEX4|D800 .. DBFF|
_UTF16_LOW_SURROGATE  = _HEX4|DC00 .. DFFF|
_utf16_ESC            = '\u' ( _HEX4 - _UTF16_HIGH_SURROGATE - _UTF16_LOW_SURROGATE )
                        '\u' _UTF16_HIGH_SURROGATE '\u' _UTF16_LOW_SURROGATE
_PRINTABLE_CHARS      = [ -]

// JSON tokens

// String
STRING_ESCAPE = _BACKSPACE_ESC
                _TAB_ESC
                _LF_ESC
                _FF_ESC
                _CR_ESC
                _DQUOTE_ESC
                _SLASH_ESC
                _BACKSLASH_ESC
                _utf16_ESC
STRING_CHARS  = ( _PRINTABLE_CHARS - '\' - '"' )
                STRING_ESCAPE
STRING        = '"' STRING_CHARS* '"'

// Number
SIGN     = '-'
INT      = 0
           [1-9] _DIGIT*
FRAC     = '.' _DIGIT+
EXP_SIGN = '+'
           '-'
EXP      = [Ee] EXP_SIGN? _DIGIT+
NUMBER   = SIGN? INT FRAC? EXP?

// Boolean
BOOLEAN = 'true'
          'false'

// Null
NULL = 'null'

// The following grammar rules allow any amount of whitespace between tokens
:GRAMMAR:

// Array
ARRAY = '[' ']'
        '[' VALUE ( ',' VALUE )* ']'

// Object
KEY_VALUE = STRING ':' VALUE
OBJECT = '{' '}'
         '{' KEY_VALUE ( ',' KEY_VALUE )* '}'

// As the last rule, it determines what gets returned
// In this case, it means a JSON primitive value is considered type JSON, as well as array and object, like SQL
VALUE = STRING
        NUMBER
        BOOLEAN
        NULL
        ARRAY
        OBJECT

END LANGUAGE
----

=== Rules that describe a language definition

----
DEFINE LANGUAGE LANGUAGE

// List of all built in identifiers
_TAB                  = U+000009
_LF                   = U+00000A
_CR                   = U+00000D
_BACKSPACE_ESC        = '\b'
_TAB_ESC              = '\t'
_LF_ESC               = '\n'
_FF_ESC               = '\f'
_CR_ESC               = '\r'
_DQUOTE_ESC           = '\"'
_SQUOTE_ESC           = "\'"
_SLASH_ESC            = '\/'
_BACKSLASH_ESC        = '\\'
_DIGIT                = [0-9]
_DIGITS               = ( _DIGIT )+
_HEX                  = [0-9A-Fa-f]
_HEX2                 = _HEX{2}
_HEX4                 = _HEX{4}
_HEX6                 = _HEX{6}
_HEX8                 = _HEX{8}
_HEX16                = _HEX{16}
_UTF16_HIGH_SURROGATE = _HEX4|D800..DBFF|
_UTF16_LOW_SURROGATE  = _HEX4|DC00..DFFF|
_UTF16_ESC            = '\u' ( _HEX4 - _UTF16_HIGH_SURROGATE - _UTF16_LOW_SURROGATE )
                        '\u' _UTF16_HIGH_SURROGATE '\u' _UTF16_LOW_SURROGATE
_UNICODE_HEX_CHAR     = 'U+' _HEX6|000000 .. 10FFFF|
_PRINTABLE_CHARS      = [ -]

// Built in identifiers can start with an underscore, but user defined identifiers cannot
IDENTIFIER = [A-Za-z][0-9A-Z_a-z]*

// A string is single or double quoted, can contain any character except opening quote character
// A string can be an identifier followed by a repetition or range
// A repetition is {N,} for N or more, {,M} for 0 up to M, or {N,M} for N up to M where N < M
// A range is |low..high|, where low < high, and both low and high must be within limits of the identifier
_NON_DQUOTE_CHARS = ( _PRINTABLE_CHARS - '"' )
_NON_SQUOTE_CHARS = ( _PRINTABLE_CHARS - "'" )
REPETITION_RANGE  = _DIGITS
                    ',' _DIGITS
                    _DIGITS ','
                    $_DIGITS ',' $_DIGITS ; $1 < $2
REPETITION        = '{' REPETITION_RANGE '}'
RANGE             = $IDENTIFIER '|' $LOW '..' $HIGH '|' ; ($2 >= lowest($1)) and ($3 <= highest($1)) and ($2 < $3)
STRING            = '"' ( _NON_DQUOTE_CHARS )* '"'
                    "'" ( _NON_SQUOTE_CHARS )* "'"
                    IDENTIFIER REPETITION
                    IDENTIFIER RANGE

// A character range of the form [X-Y], where X and Y are unicode chars or U+HHHHHH
// Valid combinations are:
// [X-], meaning char X through char U+10FFFF
// [X-Y], meaning char X thru char Y, where X < Y
// [XY...], meaning char X or char Y or ...
// [A-BCDE-F...G-], meaning char A thru char B or char C or char D or char E thru char F, ..., chars G through U+10FFFF
// In each X-Y range, X must be <= Y
// An opening square bracket can be contained inside []
// A closing square bracket cannot be contained inside [], it would have to be U+00005D
// A space or \ inside [] is a literal space or \
CHAR_RANGE_CHARS = ( _PRINTABLE_CHARS - '-' - ']' )
                   _UNICODE_HEX_CHAR
CHAR_RANGE_FROM    = CHAR_RANGE_CHARS '-'
CHAR_RANGE_FROM_TO = $CHAR_RANGE_CHARS '-' $CHAR_RANGE_CHARS; $1 < $2
CHAR_RANGE_CHOICES = CHAR_RANGE_CHARS
                     CHAR_RANGE_FROM_TO
CHAR_RANGE         = '[' ( CHAR_RANGE_CHOICES )* CHAR_RANGE_FROM ']'                

// An identifier can be followed by {N}, {N,}, {,M}, or {N,M} to indicate the number of repetitions allowed
REPETITION = IDENTIFIER '{' _DIGITS ( ',' )? '}'
             IDENTIFIER '{' ',' _DIGITS '}'
             IDENTIFIER '{' _DIGITS ',' _DIGITS '}'

// An identifier can be inside a parentheses for a grouping, which can have the following forms
// (X), (X - Y), (X - Y - Z ...)
// followed by ?, *, +, or a repetition

// RHS identifiers can be preceded by a $. A semicolon and simple comparison of $[0-9] (<, <=, =, >=, >) $[0-9] can follow RHS.
// The $[0-9] is a reference to an RHS $ usage before the semicolon.
EXPR_IDENTIFIER = '$' IDENTIFIER
EXPR_REF        = '$' [0-9]
EXPR_COMPARE = '<'
               '<='
               '='
               '>='
               '>'

:GRAMMAR:

START = 'DEFINE' 'LAANGUAGE' IDENTIFIER

EXPR = ';' EXPR_REF EXPR_COMPARE EXPR_REF

END LANGUAGE
----

=== Core language

* Multiple source files and/or directories, nested any number of levels
** A directory is a package, where the package name for a given directory is the relative directory path (without a leading ./)
** Directory and file names must begin without a dot, or they are skipped
** A directory can contain a mixture of code and non-code files
** A file within the structure can be referred to in code using an absolute path where / is the top level project dir
** Up to caller to invoke UL from correct root dir
** Invoking in a project subdir treats that subdir as root dir, so a project can be multiroot if desired
** When invoked, it is up to code to include other packages with an include path statement - any dir not included is not parsed
* A source file can have top level statements
** Allows top level ifs to be used as a type of preprocessing - conditionally define funcs and vars, conditionally include subdirs
** A program can be just top level statements in a file
